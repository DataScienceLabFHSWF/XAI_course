\chapter*{Exercise 4}
\section*{Explainable AI: CNN Interpretability with CIFAR-10 (Pre-built Tools)}

\section*{Exercise 1: Comparative Analysis }
\textbf{Packages:} torchcam vs captum

\begin{enumerate}
\item Generate explanations with both torchcam and captum 
\item Generate explanations with other methods available in the captum and torchcam library \url{https://github.com/pytorch/captum} 
\begin{minted}{python}
# Captum implementation
from captum.attr import LayerGradCam

gradcam = LayerGradCam(model, model.layer4)
attr = gradcam.attribute(inputs, target=out.argmax())
\end{minted}

\item Compare results using Quantus \url{https://github.com/understandable-machine-intelligence-lab/Quantus}
\begin{minted}{python}
from quantus import FaithfulnessCorrelation

metric = FaithfulnessCorrelation()
scores = metric(model, inputs, out.argmax(), 
               [activation_map.numpy(), attr.detach().numpy()])
\end{minted}
\end{enumerate}

\section*{Key Questions}
\begin{itemize}
\item Which package provides more intuitive visualizations?
\item How do computational costs compare?
\item Which method better highlights discriminative features?
\end{itemize}

\section*{Pre-configured Setup}
\begin{minted}{bash}
# Recommended environment
conda create -n xai python=3.8
conda install pytorch torchvision -c pytorch
pip install torchcam captum quantus pillow
\end{minted}

\section*{Sample Solutions Checklist}
\begin{itemize}
\item [ ] Working Grad-CAM visualizations for 3 classes
\item [ ] Faithfulness scores for both methods
\item [ ] Comparative analysis table
\end{itemize}
