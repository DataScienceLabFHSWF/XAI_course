\chapter*{Exercise Sheet 1}
\section*{Learning Objectives 1}
\begin{itemize}
\item Understand basic concepts of interpretable machine learning
\item Implement simple interpretable models
\item Analyze model coefficients and feature importance
\end{itemize}

\section*{Exercise 1: Linear Model Interpretation (Basics)}
\textbf{Resources:} Chapter 5.1 of textbook, Slides 15-28

\begin{enumerate}
\item Train a linear regression model on the Boston housing dataset
\item Extract and interpret the model coefficients
\item Calculate feature importance using standardized coefficients
\item Compare with Lasso regression results (feature selection)
\end{enumerate}

\begin{minted}{python}
# Starter code
from sklearn.datasets import load_boston
from sklearn.linear_model import LinearRegression, Lasso

data = load_boston()
X, y = data.data, data.target
# Add your implementation here
\end{minted}

\section*{Exercise 2: Decision Tree Analysis}
\textbf{Resources:} Chapter 5.5 of textbook, Slides 45-52

\begin{enumerate}
\item Train a decision tree classifier on the iris dataset
\item Visualize the decision tree using graphviz
\item Extract and interpret feature importance values
\item Modify tree depth and analyze impact on interpretability
\end{enumerate}

\section*{Exercise 3: Model Comparison}
\textbf{Resources:} Chapter 6 of textbook, Slides 60-65

Compare the interpretability of:
\begin{itemize}
\item Linear regression vs. decision tree
\item Global vs. local explanations
\item Model-specific vs model-agnostic methods
\end{itemize}

\section*{Submission Guidelines}
\begin{itemize}
\item Submit Jupyter notebooks with implementations and markdown explanations
\item Include visualizations of model interpretations

\end{itemize}

\section*{Recommended Resources}
\begin{itemize}
\item \href{https://christophm.github.io/interpretable-ml-book/limo.html}{LIME in Practice}
\item \href{https://scikit-learn.org/stable/}{scikit-learn Documentation}
\end{itemize}
